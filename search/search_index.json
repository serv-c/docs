{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Services","text":"<p>The microservice layer responds to requests in a nonblocking manner to the client.</p> <pre><code>block-beta\n\ncolumns 4\n\n\nspace space bus cache\nspace space space space\nrequest space\nblock:microservice:2\n  http[\"http server\"]\n  worker\nend\nspace space space space\nspace space middleware:2\nstyle worker stroke-dasharray: 5 5\n\n\nrequest --&gt; http\nhttp --&gt; bus\nhttp --&gt; cache\nbus --&gt; worker\nworker --&gt; bus\nworker --&gt; cache\nworker --&gt; middleware</code></pre> <p>A microservice will always have an HTTP server and optionally a worker.</p>"},{"location":"#http-server","title":"HTTP Server","text":"<p>The HTTP server will receive and be responsible for:</p> <ul> <li>health checks: to ensure the service is healthy</li> <li>messaging: sending messages along the bus for services to perform work</li> <li>responses: checking the cache for the response from the worker</li> <li>spawn: spawns the worker process and observes the health of the worker process</li> </ul> <p>The HTTP server is the observer to the worker and health checks should fail if the worker is not running or unhealthy. The following interface should be implemented,</p> <pre><code>classDiagram\n\nclass HTTPServer{\n  +start()\n  +stop()\n  +getId(string id) any\n  +sendMessage(WebPayload message) boolean\n  +health() boolean\n}</code></pre> <p>The server will respond to the following http interface,</p> <pre><code>GET /healthz\nGET /readyz\n      200   OK\n      &gt;400  not okay\n\nGET /id/:id\n    200   responds with the value of id in cache\n    404   value does not exist in cache\n    &gt;500  issue accessing id in cache\n\nGET /\n    200   responds with microservice information\n\nPOST /\n    200   message sent along bus\n    500   issue sending message to bus\n</code></pre> <p>The format for the microservice information will follow the identification schema.</p>"},{"location":"#worker","title":"Worker","text":"<p>The worker code should be specific to its function and maintain a connection with the bus and subscribe to a topic or queue. The subscription will allow the bus to send tasks to the service to process and complete. Middleware may need to maintain an open connection or establish as necessary.</p>"},{"location":"middleware/","title":"Middleware","text":"<p>All middleware should have the following interface.</p> <pre><code>classDiagram\n\nclass Middleware {\n  -name: str\n  +constructor(config: Config)\n  +connect()\n  +close()\n  +isOpen() boolean\n}</code></pre> <p>Where config is a key:value pair dictionary that is scoped to the middleware by its <code>name</code> property. So if the name property is 'bus', the config object will be scoped to <code>config.bus</code>.</p>"},{"location":"middleware/#cache","title":"Cache","text":"<p>The cache class is a type of component with the following interface,</p> <pre><code>classDiagram\n\nclass Middleware\nclass Cache {\n  +setKey(id, value)\n  +getKey(id) any|null\n}\n\nCache &lt;|-- Middleware</code></pre>"},{"location":"middleware/#config","title":"config","text":"<p>The configuration parameters for the default cache middleware should be the connection url.</p> <p>Parameters:</p> name type description conn_url str a string with the connection url to the middleware. Defaults to the configuration variable <code>conf.cache.url</code>"},{"location":"middleware/#setkeyid-value","title":"setKey(id, value)","text":"<p>Parameters:</p> name type description id str the key in the middleware to set value any the value to store in the middleware at location <code>id</code>"},{"location":"middleware/#getkeyid","title":"getKey(id)","text":"<p>gets the value of a key from the cache middleware</p> <p>Parameters:</p> name type description id str the key to retrieve its value from the middleware. <p>Returns:</p> <p>Either the value in the middleware, or <code>null</code> if it does not exist in the middleware.</p>"},{"location":"middleware/#bus","title":"Bus","text":"<pre><code>classDiagram\n\nclass Middleware\nclass Bus {\n  +String prefix\n  +Dict routePrefix\n\n  +connect()\n  +subscribe(route, inputHandler, onConsuming, onMessage)\n  +send(route, message) boolean\n  +emitEvent(event) boolean\n}\n\nBus &lt;|-- Middleware</code></pre>"},{"location":"middleware/#config_1","title":"config","text":"<p>Parameters:</p> name type description conn_url str The url to connect to the bus. defaults to <code>conf.bus.url</code> prefix str The prefix to use when setting up the route. Defaults to <code>conf.bus.prefix</code>"},{"location":"middleware/#subscriberoute-inputhandler-onconsuming-onmessage","title":"subscribe(route, inputHandler, onConsuming, onMessage)","text":"<p>Parameters:</p> name type description route str the route to subscribe to inputHandler INPUTHANDLER a function to handle messages routed to the service onConsuming ONCONSUMING a call back function when the service is consuming"},{"location":"middleware/#sendroute-message","title":"send(route, message)","text":"<p>Parameters:</p> name type description route str the route to subscribe to message Payload a function to handle messages routed to the service <p>Returns:</p> <p>Boolean true if successful.</p>"},{"location":"middleware/#emiteventevent","title":"emitEvent(event)","text":"<p>Parameters:</p> name type description event Event the event to emit <p>Returns:</p> <p>Boolean true if successful.</p>"},{"location":"config/","title":"Configuration","text":"<p>The configurations are all specified here. Configurations can be set through yaml configuration file using the path configured by environment variable <code>CONF__FILE</code> which will default to <code>/config/config.yaml</code>. When being set via environment variable, the <code>__</code> will represent when going down in a section and should be all uppercase. For example, <code>conf.bus.url</code> can be set via the environment variable <code>CONF__BUS__URL</code>.</p> <pre><code>conf:\n  # the location of the configuration file. Obviously can only be set via environment variables.\n  file: /config/config.yaml\n  instanceid: str   # defaults to hostname\n\n  # configuration for the bus\n  bus:\n    url: str # connection string\n    prefix: str # prefix to use when subscribing to a route\n    route: str # name used when subscribing\n\n    routemap: {} # &lt;route&gt;: prefix. if set via environment variable, will be expecting a string to be loaded via a json parser\n\n    # when about to send a 400 or 500, exit the program instead of responding with an error response. This is useful to force services to always exit cleanly in nonproduction environments.\n    exiton4XX: bool \n    exiton500: bool\n\n  cache:\n    url: str # connection string\n\n  http:\n    port: 3000\n</code></pre>"},{"location":"worker/","title":"Worker","text":"<p>The worker will process payloads as indicated below,</p> <pre><code>sequenceDiagram\n    autonumber\n\n    participant bus\n    participant cache\n    participant worker\n    participant middleware\n\n    bus-&gt;&gt;worker: payload\n    activate worker\n    worker-&gt;&gt;cache: get input\n    worker--)middleware: interface\n    middleware--)worker: interface\n    worker-&gt;&gt;cache: store response\n    deactivate worker</code></pre> <ol> <li>retrieve the payload from the bus on the queue/topic that the worker has subscribed to.</li> <li>retrieve the arguments object from the cache at key <code>arugmentId</code></li> <li>perform work while storing progress in the cache at location <code>id</code> as an artifact response. Microservices will leverage the middleware as needed to perform work. The flow of process work can be modified via worker hooks</li> <li>store the solution/response at location <code>id</code> in cache.</li> </ol> <p><code>id</code> is an optional string that represents the arguments object and the state of the system.</p> <pre><code>block-beta\n    columns 5\n\n    block:inputs\n        columns 1\n        system((\"System\"))\n        payload((\"Payload\"))\n    end\n    space\n\n    worker\n    space\n    answer((\"response\"))\n\n    inputs --&gt; worker\n    worker --&gt; answer</code></pre> <p>If the state of the system and the payload is the same, then the reponse should be the same and thus the message will not be sent over the bus. The <code>force</code> parameter when true will ensure that the message is sent on the bus regardless if there is a completed response in the cache or not.</p>"},{"location":"worker/hooks/","title":"Hooks","text":"<p>Hooks are used to modify the execution flow of a service. This is useful to perform a multitude of patterns.</p>"},{"location":"worker/hooks/oncomplete/","title":"On Complete","text":"<pre><code>\"oncomplete\": [\n    { ... }\n]\n</code></pre> <p>The on complete hook runs a series of tasks after a job has completed successfully or not. The order of execution is based on the order as presented in the array. Thus, if the first hook fails to execute, subsequent hooks will fail. No event is thrown if the hook fails to execute.</p> <p>On complete hooks are obsecure to the program executing them, and fully co-ordinated by the program sending the payload. Orchestrators can make full use of this in order to perform a workflow of tasks.</p> <pre><code>block-beta\n    orch((\"Orchestrator\"))\n    space\n\n    block:workflow\n        columns 1\n        task1[\"Task 1\"]\n        space\n        task2[\"Task 2\"]\n    end\n    space\n    answer((\"response\"))\n\n    orch --&gt; task1\n    task1 --&gt; task2\n    task2 --&gt; answer</code></pre> <p>We want to avoid having the individual tasks to know their location relative to the other tasks and leverage an orchestrator to delegate and report on the status of the pipeline. Leveraging \"on complete\" hooks we can achieve this.</p> <pre><code>block-beta\n    columns 2 \n    orch((\"Orchestrator\"))\n\n    block:workflow\n        columns 1\n        task1[\"Task 1\"]\n        space\n        task2[\"Task 2\"]\n    end\n    space\n    answer((\"response\"))\n\n    orch --&gt; task1\n    orch --&gt; task2\n    orch --&gt; answer</code></pre>"},{"location":"worker/hooks/oncomplete/#send-message-hook","title":"Send Message Hook","text":"<p>To use the send message hook, the oncomplete must be specified as below,</p> <pre><code>{\n    \"type\": \"sendmessage\",\n    \"route\": \"my-route\", // the route to send to upon completion\n    \"method\": \"my method\", // the method to send the below payload\n\n    // inputs is a non required filed. if specified, this is what is \n    // passed into 'my method' at 'my-route'. Otherwise, it is as described\n    // below,\n    \"inputs\": {\n        \"id\": \"string\",\n        \"method\": \"my method\",\n        \"inputs\": {}    // inputs will be the original input\n    }\n}\n</code></pre> <p>The schema for the payload is argument schema with the id of where the response is stored.</p> <pre><code>{\n    ...argument,\n    \"id\": \"\"\n}\n</code></pre>"},{"location":"worker/hooks/parallelize/","title":"Parallelize","text":"<pre><code>\"part\": {\n    \"part_id\": \"number\",\n    \"total_parts\": \"number\",\n    \"part_queue\": \"string\"\n}\n</code></pre> <p>The part hook identifies if there are multiple tasks running in parrallel that must be completed before continuing. Having a <code>part</code> hook decorator will block the oncomplete hook until all the parts are complete. The <code>part_queue</code> should be unique as to not conflict with other routes in the exchange. Example: <code>part.&lt;svc&gt;-&lt;method&gt;-&lt;id&gt;</code></p> <p>Note: The maximum length of a queue in AMQP is usually 255 bytes.</p> <p>The part hook is to obsecure from the client how the program is internally solving a payload. This allows the solution to be program dependent. The workflow of when a part hook is identified should be as follows,</p> <pre><code>flowchart LR\n  task&gt;Task Part i]\n  process[/Process/]\n\n  subgraph HookEval\n    direction TB\n    publish((\"Publish to part queue\"))\n    check{\"Is len(part_queue) == total_parts\"}\n    yes[/execute oncomplete hook/]\n    nothing\n\n    publish --&gt; check\n    check -- yes --&gt; yes\n    check -- no --&gt; nothing\n  end\n\n  finishflow(((return OK)))\n\n  task --&gt; process\n  process --&gt; HookEval\n  HookEval --&gt; finishflow</code></pre>"},{"location":"worker/hooks/parallelize/#creating-the-decorator","title":"Creating the Decorator","text":"<p>The decorator can be manually added or also generated by the service itself</p>"},{"location":"worker/hooks/parallelize/#generation","title":"Generation","text":"<p>If the method being triggered has a method with the suffix <code>_part</code>, the worker should follow the following flow to generate part decorators. When using the generator, the other hooks are ignored.</p> <pre><code>flowchart LR\n  task&gt;Task]\n  check{\"does method '[method]_part' exist AND no existing part decorator?\"}\n\n  method[/\"run [method]\"/]\n  yes[/execute oncomplete hook/]\n\n  partmethod[/\"run [method]_part\"/]\n  subgraph PartMethod\n    direction TB\n\n    gen[/\"make part queue\"/]\n    publish((\"publish with part decorator\"))\n    task_i&gt;Task Part i]\n    task_k&gt;Task Part k]\n\n    gen --&gt; publish\n    publish --&gt; task_i\n    publish --&gt; task_k\n  end\n\n  finishflow(((return OK)))\n\n  task --&gt; check\n  check -- yes --&gt; partmethod --&gt; PartMethod\n  check -- no --&gt; method --&gt; yes\n\n  PartMethod --&gt; finishflow\n  yes --&gt; finishflow</code></pre>"},{"location":"worker/hooks/parallelize/#use-case","title":"Use Case","text":"<p>A task can be split into smaller tasks in order to streamline workloads or deal with larger workloads in a horizontal approach. The system needs to keep track of all the splits in order to know when the oncomplete hook should be executed if needed.</p>"}]}